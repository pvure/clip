# -*- coding: utf-8 -*-
"""PRANAY CLIP AB ANTIGEN

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1QA2UVfPHWDKFZI80RVomXFDU6xs14fyv
"""

#installs
!pip install fair-esm
!pip install pytorch-lightning
!pip install transformers

#import modules

import pandas as pd
from tqdm import tqdm
import pickle
import torch
import esm
import numpy as np
import matplotlib.pyplot as plt
import random
import io
from google.colab import drive
from transformers import EsmModel, EsmTokenizer, EsmConfig, AutoTokenizer

#connect to drive
drive.mount('/content/drive')

import pytorch_lightning as pl
import torch.nn as nn
import torch.nn.functional as F
from torch.utils.data import DataLoader

"""Importing Data"""

#read dataset

path = "/content/drive/MyDrive/Programmable Biology Group/Pranay/Data/Ab_Antigen.csv" #antibody and protein target sequences


Ab_Antigen = pd.read_csv(path)

Ab_Antigen

Ab_Antigen['AB Sequence'] = Ab_Antigen['AB Sequence'].str.replace(" ", "")
Ab_Antigen['AB Sequence'] = Ab_Antigen['AB Sequence'].str.replace('\n', "")


Ab_Antigen['Target Sequence'] = Ab_Antigen['Target Sequence'].str.replace(" ", "")
Ab_Antigen['Target Sequence'] = Ab_Antigen['Target Sequence'].str.replace('\n', "")

#now I want to add a column with the length of each antibody sequence.

Ab_Antigen.insert(Ab_Antigen.columns.get_loc("AB Sequence") + 1, "Sequence Length", Ab_Antigen['AB Sequence'].apply(len))

Ab_Antigen

#import embeddings

ab_embeddings_path = "/content/drive/MyDrive/Programmable Biology Group/Pranay/Data/ab_prot_embeddings.pickle"


with open(ab_embeddings_path, 'rb') as file:
  ab_dict = pickle.load(file)

target_embeddings_path = "/content/drive/MyDrive/Programmable Biology Group/Pranay/Data/target_prot_embeddings.pickle"

with open(target_embeddings_path, 'rb') as file:
  target_dict = pickle.load(file)


for key, tensor in target_dict.items():
    new_tensor = tensor.reshape([1280])
    target_dict[key] = new_tensor

#torch dataset, matching embeddings to sequence

class ABAntigenDataset(torch.utils.data.Dataset):
   def __init__(self, ab_dict, target_dict, Ab_Antigen):
    super().__init__()
    self.ab_dict = ab_dict
    self.target_dict = target_dict
    self.Ab_Antigen = Ab_Antigen

   def __len__(self):
      return len(self.Ab_Antigen)

   def __getitem__(self, index):
    ab, target = self.Ab_Antigen.loc[index][['AB Sequence', 'Target Sequence']]
    try:
      ab_esm_embedding = ab_dict[ab]
    except KeyError as e:
      ab = ab.replace("\r", "")
      ab_esm_embedding = ab_dict[ab]

    target_esm_embedding = target_dict[target]


    return_dict = {
        "Antibody": ab,
        "Target": target,
        "antibody_input": ab_esm_embedding,
        "protein_target_input": target_esm_embedding,
    }

    return return_dict

dataset = ABAntigenDataset(ab_dict,target_dict, Ab_Antigen)
 # Index of the sample you want to retrieve

dataset[0]

import pytorch_lightning as pl
from torch.utils.data import DataLoader

class AbAntigenDataModule(pl.LightningDataModule):
    def __init__(self, Ab_Antigen, batch_size = 64):
        super().__init__()
        self.batch_size = batch_size
        self.Ab_Antigen = Ab_Antigen


    def prepare_data(self):
      self.train_df = self.Ab_Antigen.iloc[0:112]
      self.val_df = self.Ab_Antigen.iloc[112:123]
      self.test_df = self.Ab_Antigen.iloc[123:140]


    def setup(self, stage):
        self.train_dataset = ABAntigenDataset(ab_dict, target_dict, self.train_df.reset_index())
        self.val_dataset = ABAntigenDataset(ab_dict, target_dict, self.val_df.reset_index())
        self.test_dataset = ABAntigenDataset(ab_dict, target_dict, self.test_df.reset_index())

    def train_dataloader(self):
        # shuffling dataloader
        return DataLoader(self.train_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)

    def val_dataloader(self):
        full_batch = DataLoader(self.val_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)
        binary_batch = DataLoader(self.val_dataset, batch_size=2, shuffle=True, drop_last=True)

        return [full_batch, binary_batch]


    def test_dataloader(self):
        full_batch = DataLoader(self.test_dataset, batch_size=self.batch_size, shuffle=True, drop_last=True)
        binary_batch = DataLoader(self.test_dataset, batch_size=2, shuffle=True, drop_last=True)

        return [full_batch, binary_batch]

import torch.nn as nn
import torch.nn.functional as F
import pytorch_lightning as pl
from torch.utils.data import DataLoader

class MiniCLIP(pl.LightningModule):
    def __init__(self, lr):
        super().__init__()
        self.lr = lr


        self.prot_embedder = nn.Sequential(
          nn.Linear(1280, 640),
          nn.ReLU(),
          nn.Linear(640, 320),
        )


        self.ab_embedder = nn.Sequential(
          nn.Linear(1280, 640),
          nn.ReLU(),
          nn.Linear(640, 320),
        )

    def forward(self, ab_input, prot_input):

        ab_embedding = F.normalize(self.ab_embedder(ab_input))
        prot_embedding = F.normalize(self.prot_embedder(prot_input))

        logits = torch.matmul(ab_embedding, prot_embedding.T)

        return logits

    def training_step(self, batch, batch_idx):

        logits = self(
            batch['antibody_input'],
            batch['protein_target_input'],
        )

        batch_size = batch['antibody_input'].shape[0]
        labels = torch.arange(batch_size).to(self.device)



        partner_prediction_loss = F.cross_entropy(logits, labels)


        antibody_prediction_loss = F.cross_entropy(logits.T, labels)

        loss = (partner_prediction_loss + antibody_prediction_loss) / 2

        self.log("train_loss", loss, sync_dist=True, batch_size=logits.shape[0])
        self.log("train_partner_prediction_loss", partner_prediction_loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0])
        self.log("train_antibody_prediction_loss", antibody_prediction_loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0])

        return loss

    def validation_step(self, batch, batch_idx, dataloader_idx=0):
        if dataloader_idx == 0 or dataloader_idx == 2:
          if dataloader_idx == 0:
            prefix = "generic"
          else:
            prefix = "antibody"


          logits = self(
              batch['antibody_input'],
              batch['protein_target_input'],
          )

          batch_size = batch['antibody_input'].shape[0]
          labels = torch.arange(batch_size).to(self.device)


          partner_prediction_loss = F.cross_entropy(logits, labels)

          antibody_prediction_loss = F.cross_entropy(logits.T, labels)

          loss = (partner_prediction_loss + antibody_prediction_loss) / 2



          antibody_predictions = logits.argmax(dim=0)

          partner_predictions = logits.argmax(dim=1)

          antibody_ranks = logits.argsort(dim=0).diag() + 1
          antibody_mrr = (antibody_ranks).float().pow(-1).mean()

          partner_ranks = logits.argsort(dim=1).diag() + 1
          partner_mrr = (partner_ranks).float().pow(-1).mean()

          partner_accuracy = partner_predictions.eq(labels).float().mean()
          antibody_accuracy = antibody_predictions.eq(labels).float().mean()

          k = int(logits.shape[0] / 10)
          antibody_topk_accuracy = torch.any((logits.topk(k, dim=0).indices - labels.reshape(1, -1)) == 0, dim=0).sum() / logits.shape[0]
          partner_topk_accuracy = torch.any((logits.topk(k, dim=1).indices - labels.reshape(-1, 1)) == 0, dim=1).sum() / logits.shape[0]


          self.log(f"{prefix}_val_loss", loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_perplexity", torch.exp(loss), sync_dist=False, prog_bar=True, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_partner_prediction_loss", partner_prediction_loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_antibody_prediction_loss", antibody_prediction_loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_partner_perplexity", torch.exp(partner_prediction_loss), sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_antibody_perplexity", torch.exp(antibody_prediction_loss), sync_dist=True, prog_bar=True, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_partner_accuracy", partner_accuracy, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_antibody_accuracy", antibody_accuracy, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_partner_top10p", partner_topk_accuracy, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_antibody_top10p", antibody_topk_accuracy, sync_dist=True, prog_bar=True, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_antibody_mrr", antibody_mrr, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_val_partner_mrr", partner_mrr, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)

        else:
          if dataloader_idx == 1:
            prefix = "generic"
          else:
            prefix = "antibody"


          logits = self(
              batch['antibody_input'],
              batch['protein_target_input'],
          )

          batch_size = batch['antibody_input'].shape[0]
          labels = torch.arange(batch_size).to(self.device)


          binary_cross_entropy = F.cross_entropy(logits.T, labels)

          binary_predictions = logits.argmax(dim=0)
          binary_accuracy = binary_predictions.eq(labels).float().mean()

          self.log(f"{prefix}_binary_loss", binary_cross_entropy, sync_dist=True, prog_bar=False, batch_size=2, add_dataloader_idx=False)
          self.log(f"{prefix}_binary_accuracy", binary_accuracy, sync_dist=False, prog_bar=True, batch_size=2, add_dataloader_idx=False)


    def test_step(self, batch, batch_idx, dataloader_idx=0):

        if dataloader_idx == 0 or dataloader_idx == 2:
          if dataloader_idx == 0:
            prefix = "generic"
          else:
            prefix = "antibody"


          logits = self(
              batch['antibody_input'],
              batch['protein_target_input'],
          )

          batch_size = batch['antibody_input'].shape[0]
          labels = torch.arange(batch_size).to(self.device)
          partner_prediction_loss = F.cross_entropy(logits, labels)


          antibody_prediction_loss = F.cross_entropy(logits.T, labels)

          loss = (partner_prediction_loss + antibody_prediction_loss) / 2



          antibody_predictions = logits.argmax(dim=0)

          partner_predictions = logits.argmax(dim=1)

          antibody_ranks = logits.argsort(dim=0).diag() + 1
          antibody_mrr = (antibody_ranks).float().pow(-1).mean()

          partner_ranks = logits.argsort(dim=1).diag() + 1
          partner_mrr = (partner_ranks).float().pow(-1).mean()

          partner_accuracy = partner_predictions.eq(labels).float().mean()
          antibody_accuracy = antibody_predictions.eq(labels).float().mean()

          k = int(logits.shape[0] / 10)
          antibody_topk_accuracy = torch.any((logits.topk(k, dim=0).indices - labels.reshape(1, -1)) == 0, dim=0).sum() / logits.shape[0]
          partner_topk_accuracy = torch.any((logits.topk(k, dim=1).indices - labels.reshape(-1, 1)) == 0, dim=1).sum() / logits.shape[0]


          self.log(f"{prefix}_test_loss", loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_perplexity", torch.exp(loss), sync_dist=False, prog_bar=True, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_partner_prediction_loss", partner_prediction_loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_antibody_prediction_loss", antibody_prediction_loss, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_partner_perplexity", torch.exp(partner_prediction_loss), sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_antibody_perplexity", torch.exp(antibody_prediction_loss), sync_dist=True, prog_bar=True, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_partner_accuracy", partner_accuracy, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_antibody_accuracy", antibody_accuracy, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_partner_top10p", partner_topk_accuracy, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_antibody_top10p", antibody_topk_accuracy, sync_dist=True, prog_bar=True, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_antibody_mrr", antibody_mrr, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)
          self.log(f"{prefix}_test_partner_mrr", partner_mrr, sync_dist=True, prog_bar=False, batch_size=logits.shape[0], add_dataloader_idx=False)

        else:
          if dataloader_idx == 1:
            prefix = "generic"
          else:
            prefix = "antibody"


          logits = self(
              batch['antibody_input'],
              batch['protein_target_input'],
          )

          batch_size = batch['antibody_input'].shape[0]
          labels = torch.arange(batch_size).to(self.device)


          binary_cross_entropy = F.cross_entropy(logits.T, labels)

          binary_predictions = logits.argmax(dim=0)
          binary_accuracy = binary_predictions.eq(labels).float().mean()

          self.log(f"{prefix}_test_binary_loss", binary_cross_entropy, sync_dist=True, prog_bar=False, batch_size=2, add_dataloader_idx=False)
          self.log(f"{prefix}_test_binary_accuracy", binary_accuracy, sync_dist=False, prog_bar=True, batch_size=2, add_dataloader_idx=False)


    def configure_optimizers(self):
        return torch.optim.Adam(self.parameters(), lr=self.lr)

from pytorch_lightning.callbacks.early_stopping import EarlyStopping



early_stop_callback = EarlyStopping(
   monitor='generic_binary_loss',
   min_delta=0.00,
   patience=8,
   verbose=False,
   mode='min'
)

datamodule = AbAntigenDataModule(Ab_Antigen)
miniclip = MiniCLIP(lr = 0.000005)
trainer = pl.Trainer(callbacks=[early_stop_callback])

trainer.fit(miniclip, datamodule=datamodule)

trainer.validate(miniclip, datamodule=datamodule)

trainer.test(miniclip, datamodule=datamodule)

# Commented out IPython magic to ensure Python compatibility.
# %reload_ext tensorboard
# %tensorboard --logdir lightning_logs/

"""trainer.fit(miniclip, datamodule=datamodule)"""